%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Linear least-squares for data approximation.
%   Given the least-squares problem: min||Ax ? b||^2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
clear;
clc;

%Test 1
x = [1.0; 1.2; 1.4; 1.6; 1.8; 2.0;
     2.2; 2.4; 2.6; 2.8; 3.0];
b = [1.18; 1.26; 1.23; 1.37; 1.37;
     1.45; 1.42; 1.46; 1.53; 1.59; 1.50];
 
[M,N] = size(x);

A = [ones(M,1), x, x.^2, x.^3, x.^4];
%Computing and displaying the matrix condition number
condition_number = cond(A)

%computeing solution with the normal equations
%computation of A'A may be affected by a loss of significant
%digits, with a consequent loss of the positive definiteness of the matrix itself.
x_cholescky = inv(A'*A)*A'*b;

%computeing solution by using the pseudoinverse of A
psudo_solution_x =  pinv(A)*b;

%[Q,R]=qr(A);
%Qt=Q(: ,1:2); Rt=R(1:2 ,:);
%xstar = Rt \ (Qt'*b)

%GIven a data set of m data (xi, yi), i = 1, . . . m, 
%determine the least-squares polynomial approximation of degree n = 1, . . . 5 of the data

for i = 2 : 5
    A = ones(M,1);
    for k = 2 : i
        A = [A, x.^(k-1)];        
    end
    psudo_solution_x =  pinv(A)*b;
    f = polyval(psudo_solution_x,x);
    figure(1);
    subplot(2,3,i-1)
    plot(x,b,'o', x,f,'-')
    title(join(["Least-Squares Polynomial Approximation of degree =", int2str(i)]))
    legend('data','linear fit')
    % A = [ones(M,1, )x, x.^2, x.^3, x.^4];
    
    p = polyfit(x,b,i)
    f = polyval(p,x);
    figure(2);
    subplot(2,3,i-1)
    plot(x,b,'o', x,f,'-')
    title(join(["Using Polyfit: Least-Squares Polynomial Approximation of degree =", int2str(i)]))
    legend('data','linear fit')
    
    %Compute the R2 value:
    miu = mean(b);
    s0 = 0;
    s1 = 0;
    for j = 1 : M
        s0 = s0 + (b(j) - f(j))^2;
        s1 = s1 + (b(j) - miu)^2;   
    end
    R_squarded = 1 - (s0/s1);
    fprintf(["R2 value for Least-Squares Polynomial Approximation of degree %i is equal to %2.16f\n"],i , R_squarded);
    
end

